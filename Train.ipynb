{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/superguine/ODProject/blob/main/Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation Section"
      ],
      "metadata": {
        "id": "3UgSOSgCMFyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks for GPU and lists them.\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "in7fD3qqMPO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the tensorflow models repository from GitHub\n",
        "!pip uninstall Cython -y # Temporary fix for \"No module named 'object_detection'\" error\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "0Sk3yQJwMW7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy setup files into models/research folder\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "#cp object_detection/packages/tf2/setup.py ."
      ],
      "metadata": {
        "id": "mQwBzGT4MW5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify setup.py file to install the tf-models-official repository targeted at TF v2.17.0\n",
        "import re\n",
        "with open('/content/models/research/object_detection/packages/tf2/setup.py') as f:\n",
        "    s = f.read()\n",
        "\n",
        "with open('/content/models/research/setup.py', 'w') as f:\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('tf-models-official>=2.5.1',\n",
        "               'tf-models-official==2.8.0', s)\n",
        "    f.write(s)"
      ],
      "metadata": {
        "id": "EldPCYnoMWym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to do a temporary fix with PyYAML because Colab isn't able to install PyYAML v5.4.1\n",
        "!pip install pyyaml==5.3\n",
        "!pip install /content/models/research/\n",
        "\n",
        "\n",
        "# Need to downgrade to TF v2.8.0 due to Colab compatibility bug.\n",
        "!pip install tensorflow==2.8.0\n",
        "\n",
        "# Install CUDA version 11.0 (to maintain compatibility with TF v2.8.0)\n",
        "!pip install tensorflow_io==0.23.1\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
        "!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "!wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n",
        "!apt-get update && sudo apt-get install cuda-toolkit-11-0\n",
        "!export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH\n"
      ],
      "metadata": {
        "id": "DlgbDD38MWtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test installation"
      ],
      "metadata": {
        "id": "8QmkwR44NUAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "XX-spWpqMWps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bWYIzztSUiXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset collecting Section"
      ],
      "metadata": {
        "id": "UC6Pl10BUjb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Skip this cell !!\n",
        "\n",
        "drive_link = \"< drive folder link >\"\n",
        "\n",
        "\n",
        "def create_folder_download_link(drive_link):\n",
        "    # Extract the folder ID from the provided Google Drive link\n",
        "    folder_id = drive_link.split('/folders/')[1].split('?')[0]\n",
        "\n",
        "    # Construct the download link using the extracted folder ID\n",
        "    download_link = f\"https://drive.google.com/drive/folders/{folder_id}?usp=sharing\"\n",
        "\n",
        "    return download_link\n",
        "\n",
        "download_link = create_folder_download_link(drive_link)\n",
        "print(f\"Download link: {download_link}\")\n",
        "\n",
        "# Download the content\n",
        "!wget -O /content/images.zip download_link"
      ],
      "metadata": {
        "id": "MtAkFRH0UyCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/images\n",
        "!unzip -q images.zip -d /content/images/all\n",
        "!mkdir /content/images/train; mkdir /content/images/validation; mkdir /content/images/test"
      ],
      "metadata": {
        "id": "Vs_FdMZ6VNqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/superguine/ODProject/main/split.py\n",
        "!python train_val_test_split.py"
      ],
      "metadata": {
        "id": "eySns0eTXf3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### This creates a a \"labelmap.txt\" file with a list of classes the object detection model will detect.\n",
        "%%bash\n",
        "cat <<EOF >> /content/labelmap.txt\n",
        "class1\n",
        "class2\n",
        "class3\n",
        "EOF"
      ],
      "metadata": {
        "id": "u8RHLxvZXl4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data conversion scripts\n",
        "! wget https://raw.githubusercontent.com/superguine/ODProject/main/csv.py\n",
        "! wget https://raw.githubusercontent.com/superguine/ODProject/main/tfrecord.py"
      ],
      "metadata": {
        "id": "B9zrYx7FXs15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CSV data files and TFRecord files\n",
        "!python3 create_csv.py\n",
        "!python3 create_tfrecord.py --csv_input=images/train_labels.csv --labelmap=labelmap.txt --image_dir=images/train --output_path=train.tfrecord\n",
        "!python3 create_tfrecord.py --csv_input=images/validation_labels.csv --labelmap=labelmap.txt --image_dir=images/validation --output_path=val.tfrecord"
      ],
      "metadata": {
        "id": "NOPnrZyHYDmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the locations of the TFRecord and labelmap files as variables\n",
        "train_record_fname = '/content/train.tfrecord'\n",
        "val_record_fname = '/content/val.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/labelmap.pbtxt'"
      ],
      "metadata": {
        "id": "OJYCvfd-YIn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Section"
      ],
      "metadata": {
        "id": "EbR67Mvi_2iP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configuring for training"
      ],
      "metadata": {
        "id": "zKPqtL95LURN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\n",
        "chosen_model = 'ssd-mobilenet-v2'\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd-mobilenet-v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "    'efficientdet-d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
        "    },\n",
        "    'ssd-mobilenet-v2-fpnlite-320': {\n",
        "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "}\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
      ],
      "metadata": {
        "id": "kdCNain2AMWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the pretrained model file and configuration file."
      ],
      "metadata": {
        "id": "74wta-pzAs_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create \"mymodel\" folder for holding pre-trained weights and configuration files\n",
        "%mkdir /content/models/mymodel/\n",
        "%cd /content/models/mymodel/\n",
        "\n",
        "# Download pre-trained model weights\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Download training configuration file for model\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ],
      "metadata": {
        "id": "I06qvPpxAr8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training parameters for the model\n",
        "num_steps = 4000\n",
        "\n",
        "if chosen_model == 'efficientdet-d0':\n",
        "  batch_size = 4\n",
        "else:\n",
        "  batch_size = 16"
      ],
      "metadata": {
        "id": "UvAgqNkkBO33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set file locations and get number of classes for config file\n",
        "pipeline_fname = '/content/models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "print('Total classes:', num_classes)\n"
      ],
      "metadata": {
        "id": "kBpXpnKsBRQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "import re\n",
        "\n",
        "%cd /content/models/mymodel\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # Set tfrecord files for train and test datasets\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    # Set label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set batch_size\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n",
        "    if chosen_model == 'ssd-mobilenet-v2':\n",
        "      s = re.sub('learning_rate_base: .8',\n",
        "                 'learning_rate_base: .08', s)\n",
        "\n",
        "      s = re.sub('warmup_learning_rate: 0.13333',\n",
        "                 'warmup_learning_rate: .026666', s)\n",
        "\n",
        "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
        "    if chosen_model == 'efficientdet-d0':\n",
        "      #s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
        "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
        "      s = re.sub('min_dimension', 'height', s)\n",
        "      s = re.sub('max_dimension', 'width', s)\n",
        "\n",
        "    f.write(s)\n"
      ],
      "metadata": {
        "id": "yNvsIfycBUnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) Display the custom configuration file's contents\n",
        "!cat /content/models/mymodel/pipeline_file.config"
      ],
      "metadata": {
        "id": "L21rj9b1BkGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the custom config file and the directory to store training checkpoints in\n",
        "pipeline_file = '/content/models/mymodel/pipeline_file.config'\n",
        "model_dir = '/content/training/'"
      ],
      "metadata": {
        "id": "zHnpZzDOBnfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#launching Tensorboard session\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/train'"
      ],
      "metadata": {
        "id": "h6ZlLtEGB4aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  > **NOTE:**  It won't show anything yet, because we haven't started training. Once training starts, come back and click the refresh button to see the model's overall loss."
      ],
      "metadata": {
        "id": "mTqe0q4gCEEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Start training"
      ],
      "metadata": {
        "id": "fgJTmIk3JlwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training!\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1"
      ],
      "metadata": {
        "id": "gHcaZVlDECqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model exportation, testing & download Section"
      ],
      "metadata": {
        "id": "ICjniVdmh1_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Export model"
      ],
      "metadata": {
        "id": "E-xZ47AaJ_TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a directory to store the trained TensorFlow model\n",
        "!mkdir /content/custom_model\n",
        "output_directory = '/content/custom_model'\n",
        "\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = '/content/training'\n",
        "\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --pipeline_config_path {pipeline_file} \\\n",
        "    --output_directory {output_directory}\n"
      ],
      "metadata": {
        "id": "W-ZrCcPNHUGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Inference test images"
      ],
      "metadata": {
        "id": "uJGz6PTxJfQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "### Define function for inferencing with TensorFlow model and displaying results\n",
        "\n",
        "def tf_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=10, savepath='/content/results', txt_only=False):\n",
        "\n",
        "    # Grab filenames of all images in test folder\n",
        "    images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')\n",
        "\n",
        "    # Load the label map into memory\n",
        "    with open(lblpath, 'r') as f:\n",
        "        labels = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    # Load the TensorFlow model\n",
        "    model = tf.saved_model.load(modelpath)\n",
        "    infer = model.signatures['serving_default']\n",
        "\n",
        "    # Randomly select test images\n",
        "    images_to_test = random.sample(images, num_test_images)\n",
        "\n",
        "    # Loop over every image and perform detection\n",
        "    for image_path in images_to_test:\n",
        "\n",
        "        # Load image and resize to expected shape [1xHxWx3]\n",
        "        image = cv2.imread(image_path)\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        imH, imW, _ = image.shape\n",
        "        input_tensor = tf.convert_to_tensor(image_rgb)\n",
        "        input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "        # Perform the actual detection by running the model with the image as input\n",
        "        detections = infer(input_tensor)\n",
        "\n",
        "        # Retrieve detection results\n",
        "        boxes = detections['detection_boxes'][0].numpy() # Bounding box coordinates of detected objects\n",
        "        classes = detections['detection_classes'][0].numpy().astype(np.int32) # Class index of detected objects\n",
        "        scores = detections['detection_scores'][0].numpy() # Confidence of detected objects\n",
        "\n",
        "        detection_results = []\n",
        "\n",
        "        # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
        "        for i in range(len(scores)):\n",
        "            if ((scores[i] > min_conf) and (scores[i] <= 1.0)):\n",
        "\n",
        "                # Get bounding box coordinates and draw box\n",
        "                # Coordinates are normalized, so we multiply them by the image dimensions to get pixel values\n",
        "                ymin = int(max(1, (boxes[i][0] * imH)))\n",
        "                xmin = int(max(1, (boxes[i][1] * imW)))\n",
        "                ymax = int(min(imH, (boxes[i][2] * imH)))\n",
        "                xmax = int(min(imW, (boxes[i][3] * imW)))\n",
        "\n",
        "                cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n",
        "\n",
        "                # Draw label\n",
        "                object_name = labels[classes[i] - 1] # Adjust for zero-indexing in labels\n",
        "                label = '%s: %d%%' % (object_name, int(scores[i] * 100)) # Example: 'person: 72%'\n",
        "                labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size\n",
        "                label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
        "                cv2.rectangle(image, (xmin, label_ymin - labelSize[1] - 10),\n",
        "                              (xmin + labelSize[0], label_ymin + baseLine - 10),\n",
        "                              (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n",
        "                cv2.putText(image, label, (xmin, label_ymin - 7),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text\n",
        "\n",
        "                detection_results.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n",
        "\n",
        "        # Display or save the image with detections\n",
        "        if not txt_only: # \"text_only\" controls whether we want to display the image results or just save them in .txt files\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            plt.figure(figsize=(12, 16))\n",
        "            plt.imshow(image)\n",
        "            plt.show()\n",
        "\n",
        "        # Save detection results in .txt files (for calculating mAP)\n",
        "        else:\n",
        "            # Get filenames and paths\n",
        "            image_fn = os.path.basename(image_path)\n",
        "            base_fn, ext = os.path.splitext(image_fn)\n",
        "            txt_result_fn = base_fn + '.txt'\n",
        "            txt_savepath = os.path.join(savepath, txt_result_fn)\n",
        "\n",
        "            # Write results to text file\n",
        "            # (Using format defined by https://github.com/Cartucho/mAP, which will make it easy to calculate mAP)\n",
        "            with open(txt_savepath, 'w') as f:\n",
        "                for detection in detection_results:\n",
        "                    f.write('%s %.4f %d %d %d %d\\n' %\n",
        "                            (detection[0], detection[1], detection[2],\n",
        "                             detection[3], detection[4], detection[5]))\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "LorN9Ma6Hx8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up variables for running user's model\n",
        "PATH_TO_IMAGES = '/content/images/test'   # Path to test images folder\n",
        "PATH_TO_MODEL = '/content/custom_model/custom_model'   # Path to the SavedModel directory\n",
        "PATH_TO_LABELS = '/content/labelmap.txt'   # Path to labelmap.txt file\n",
        "min_conf_threshold = 0.5   # Confidence threshold (try changing this to 0.01 if you don't see any detection results)\n",
        "images_to_test = 10   # Number of images to run detection on\n",
        "\n",
        "# Run inferencing function!\n",
        "tf_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)\n"
      ],
      "metadata": {
        "id": "wkde9Cz5Jz_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculate mAP"
      ],
      "metadata": {
        "id": "EjCiBKdxKQUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mAP\n",
        "!python calculate_map_cartucho.py --labels=/content/labelmap.txt"
      ],
      "metadata": {
        "id": "LzXWdq9rKYFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download the model"
      ],
      "metadata": {
        "id": "ui-UlVw_K5bW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move labelmap and pipeline config files into TFLite model folder and zip it up\n",
        "!cp /content/labelmap.txt /content/custom_model\n",
        "!cp /content/labelmap.pbtxt /content/custom_model\n",
        "!cp /content/models/mymodel/pipeline_file.config /content/custom_model\n",
        "\n",
        "%cd /content\n",
        "!zip -r custom_model.zip custom_model"
      ],
      "metadata": {
        "id": "dtjjo4AXKZG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/custom_model.zip')"
      ],
      "metadata": {
        "id": "V8aJyqc8LKCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}